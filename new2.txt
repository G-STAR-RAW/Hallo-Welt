hello
	Redis相关
可以理解成存储在内存中的数据库，读写速度快。广泛应用于缓存方向。
高性能键值对的内存数据库，是一种NoSQL(非关系型)数据库。
1	为什么要用Redis/为什么要用缓存
	高性能：用户第一次访问数据库的数据，因为是从硬盘上读取，所以速度是很慢的。这时把读取的数据保存在缓存中，后续用户再次访问这些数据就可以直接从缓存中获取，操作缓存就是操作内存，所以速度很快。如果数据库中相应数据改变之后，修改缓存中对应数据即可。
	高并发：直接操作缓存能承受的请求数是远远大于直接操作数据库的，可以把数据库中的部分数据转移到缓存中去，将用户的一部分数据请求直接转到缓存而不是数据库。
2	redis和memcached的区别
	Memcached仅支持简单的string数据类型，而Redis支持string、list、set、zset、hash等多种数据类型。
	当物理内存用尽后，redis可以将一些很久没用的value存储到磁盘中
	Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用
	存储数据安全--memcache挂掉后，数据没了；redis可以定期保存到磁盘（持久化）
3	Redis数据类型有哪些？
字符串(String)，散列类型(hash)，列表类型(list)，集合类型(set)，有序集合类型(zset)
3.1	String
	常用指令：set、get、decr、incr、mget
	常用于常规计数：微博数、粉丝数等
3.1.1	编码
	Int
	raw(保存大于32字节的字符串)
	embstr(保存小于等于32字节的字符串)。
	raw和embstr都是SDS结构，效果相同，不同点在于，内存分配与释放，raw两次，embstr一次。
	int编码和embstr编码如果做追加字符串等操作，满足条件下会被转换为raw编码。
	embstr编码的对象是只读的，一旦修改会先转码到raw。
 
3.2	Hash
	常用指令：hset、hget、hgetall
	常用于存储对象
3.2.1	编码
	ziplist(压缩列表->key-value键值对是以紧密相连的方式放入压缩链表的，先把key放入表尾，再放入value；键值对总是向表尾添加。)
 
	hashtable(底层为字典->每个key-value对都使用一个字典键值对来保存。)
 
哈希对象使用ziplist编码需要满足两个条件：一是所有键值对的键和值的字符串长度都小于64字节；二是键值对数量小于512个；不满足任意一个都使用hashtable编码。

3.3	List（本质为双向链表）
	常用指令：lpush、rpush、lpop、rpop、lrange
	lrange，从某个元素开始读取多少个元素，基于list实现分页查询
	常用于微博的关注列表、粉丝列表等功能。
3.3.1	编码
	ziplist(压缩列表->每个压缩列表节点保存一个元素)
	linkedlist(双端链表->每个双端链表节点都保存了一个字符串对象，在每个字符串对象内保存了一个列表元素)
列表对象使用ziplist编码需要满足两个条件：一是所有字符串长度都小于64字节，二是元素数量小于512，不满足任意一个都会使用linkedlist编码。
 
 
3.4	Set
	常用指令：sadd、spop、smembers、sunion
	常用于存储一个元素不重复的列表数据。
3.4.1	编码
	inset(底层为整数集合)
 
	hashtable(底层为字典->字典的每个键都是一个字符串对象，保存一个集合元素，不同的是字典的值都是NULL)
 
集合对象使用intset编码需要满足两个条件：一是所有元素都是整数值；二是元素个数小于等于512个；不满足任意一条都将使用hashtable编码。
3.5	zset
	常用指令：zadd、zrange、zrem、zcard
	常用于需要进行排序的元素不重复的列表数据
	与Set相比，结构上增加了一个权重参数score，用于集合中的元素排序
3.5.1	编码
	ziplist(压缩列表->两个紧密相连的压缩列表节点，第一个保存元素的成员，第二个保存元素的分值，而且分值小的靠近表头，大的靠近表尾。)
 
	skiplist(跳跃表和字典)
每个跳跃表节点都保存一个集合元素，并按分值从小到大排列；节点的object属性保存了元素的成员，score属性保存分值；
字典的每个键值对保存一个集合元素，字典的键保存元素的成员，字典的值保存分值。
 
 
有序集合对象使用ziplist编码需要满足两个条件：一是所有元素长度小于64字节；二是元素个数小于128个；不满足任意一条件将使用skiplist编码。

4	zset数据类型是如何排序的？
Zset有序集合和set类似，是不包含相同字符串的集合，但zset的每个成员都关联着一个分数值(double)，该分数值在插入成员的时候制定，这个分数值用于把zset中的成员按照最低分到最高分排列。若分数值相同，则按照value的字典顺序排序
添加元素：zadd [key] [sore1] [value1] [score2] [value2]
5	redis的Hash的时间复杂度是多少？
HSET：将key对应的Hash中的field设置为value。如果该Hash不存在，会自动创建一个。时间复杂度O(1)
HGET：返回指定Hash中field字段的值，时间复杂度O(1)
HMSET/HMGET：同HSET和HGET，可以批量操作同一个key下的多个field，时间复杂度：O(N)，N为一次操作的field数量
HSETNX：同HSET，但如field已经存在，HSETNX不会进行任何操作，时间复杂度O(1)
HEXISTS：判断指定Hash中field是否存在，存在返回1，不存在返回0，时间复杂度O(1)
HDEL：删除指定Hash中的field（1个或多个），时间复杂度：O(N)，N为操作的field数量
HINCRBY：同INCRBY命令，对指定Hash中的一个field进行INCRBY，时间复杂度O(1) 

6	Redis如何做项目的中间缓存层？
在项目中使用Redis缓存流程：
1.查询时先从缓存中查询
2.缓存中如果没有数据再从数据库查询，并将数据保存进缓存
3.如果缓存中查询到数据，直接返回，不再需要查询数据库
收益：
1、	加速读写；
2、	降低后端负载，减少后端访问量和复杂计算
成本：
1、	数据不一致(同步缓存层和存储层)；
2、	需要同时维护缓存层和存储层，增加了代码维护成本。 

7	设置redis键的过期时间
expire key seconds
redis通过定期删除+惰性删除来清理已过期的键值对
	定期删除：默认每隔100秒就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除；
	惰性删除：因为定期删除是随机抽取，所以可能会有很多的过期的key依然存在于内存中。此时，如果系统查询一个key，并且该key已经过期，则删除掉该key，且不返回value给系统。

然而，通过定期删除和惰性删除，也有可能导致大量的过期key堆积在内存中，导致redis内存耗尽。针对此问题，redis提供了6种数据淘汰机制：
	Volatile-lru:从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
	Volatile-ttl:从已设置过期时间的数据集中挑选将要过期的数据淘汰
	Volatile-random：从已设置过期时间的数据集中任意选择数据淘汰
	Allkeys-lru：从所有键中，移除最近最少使用的key
	Allkeys-random：从数据集中任意选择数据淘汰
	No-eviction：内存不足以容纳新写入数据时，写入操作报错。

volatile为前缀的策略都是从已过期的数据集中进行淘汰。
allkeys为前缀的策略都是面向所有key进行淘汰。
LRU（least recently used）最近最少用到的。
它们的触发条件都是Redis使用的内存达到阈值时。

8	~~~keys和scan

9	Redis如何缓存10万条数据
Redis管道，客户端可以一次性发送多条命令，不用逐条等待命令的返回值，而是在最后一次性读取返回结果。(好处是只需要一次网络传输开销)。

10	redis的持久化机制
Redis的持久化机制，目的在于故障恢复、灾难恢复、数据恢复。在redis宕机后，迅速使redis变得可用，并恢复宕机前的数据。
Redis的内存大小是一定的，当内存上升到一定大小的时候，redis就会触发数据淘汰机制，自动将一部分数据从内存中清除。
10.1	RDB（快照）
Redis默认的持久化机制。对redis中的数据执行周期性的持久化操作。比如每隔几分钟/几小时/几天，会生成当前时刻redis内存中数据的一份完整快照。
RDB会生成多个数据文件。
	可以在redis.conf配置文件中进行配置：
Save 900 10	每隔900秒，在这900秒时间内，如果有>=10个键发生变化，则生成当前时刻的快照文件。
优点：
	基于RDB文件来重启和恢复redis数据，效率高；
	RDB操作对redis主进程的影响非常小，因为redis只需要fork一个子进程，让子进程来进行RDB的持久化操作，使redis主进程保持高性能
缺点：
	相较于AOF，RDB在进行灾难恢复时可能会丢失更多的数据。一般情况下，RDB每隔5分钟生成一次快照文件，那么宕机时，就可能会丢失5分钟的redis数据。
	Redis在通过RDB文件恢复数据时，如果文件特别大，可能会导致对客户端提供的服务暂停数毫秒，甚至数秒。

10.2	AOF（只追加文件）
	将每条写命令作为日志，以append-only的方式写入一个日志文件，在redis重启时，通过重新执行日志中的写入指令来重构整个数据
AOF的3中持久化方式为：
appendfsync always	每次有数据修改发生时都写入AOF文件，操作频繁，降低redis速度
appendfsync everysec	每秒钟同步一次，显示地将多个写命令写入到硬盘
appendfsync no		系统决定何时进行同步
优点：
	灾难恢复时，数据丢失较少。Redis一般每秒进行一次写命令同步，最多就会丢失1秒的数据。
	Append-only模式写入，写入性能高，不会重新生成文件，没有磁盘寻址的开销。
	AOF日志文件过大的时候，会出现后台重写操作，对其中的指令进行压缩，创建出一份能够恢复数据的最小日志，也不会影响客户端的读写。

缺点：
	相同数量的数据集，AOF文件通常要大于RDB。恢复速度慢。
	AOF基于写命令的数据恢复，相较于RDB快照文件恢复，更加脆弱，容易出bug。

10.3	AOF重写
Redis主线程会创建一个子进程生成新的AOF文件。当AOF日志文件达到一定大小时，会进行AOF重写。
首先，redis会维护一个重写缓冲区，用于在子进程创建新的AOF文件期间，记录服务器执行的所有写命令。
然后，子进程会读取数据库中的键值对，生成一份能恢复数据的最小日志文件。
新的AOF文件生成后，redis主进程会将重写缓冲区中新增的写命令追加到新的AOF日志文件中，然后完成新旧AOF文件的替换。

AOF重写过程中，不需要对原有AOF文件进行任何的读取、写入、分析等操作。

11	缓存相关问题
11.1	缓存穿透
大量请求缓存中和数据库不存在的数据。
大量用户请求缓存中和数据库中不存在的数据，导致所有请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决方案：
	布隆过滤器
布隆过滤器的底层是一个位数组，数组的每个元素只能是0和1。
添加数据时，将数据通过多个hash算法，映射到位数组中的不同位置，并将该位置为1。
查询数据时，通过多个hash算法，找出查询数据在位数组中占据的位置，若所占位置全部为1，则说明该数据存在。
优点：不存储完整的数据，所以占用内存小，查询速度快；
缺点：hash算法映射的地址可能会重复，只能判断数据一定不存在，无法判断数据一定存在，有一定的误判率。且只支持新增和查询，不支持删除操作。
	缓存空对象
当持久层不命中时，即使返回的空对象也存储在缓存中，并设置一个过期时间，之后再访问这个空数据就不用再去请求数据库。（防止用户反复用同一个id进行暴力攻击）
会存储很多无用的空键，占用缓存空间。

11.2	缓存击穿
大量请求缓存中同一个失效的热点key数据。
大量用户并发对缓存中的同一个热点key进行请求，当该热点key失效的时候，持续的大并发请求就击穿缓存，直接请求数据库，导致数据库短时间承受大量请求而崩溃。

解决方案：
	设置热点key永不过期
	互斥锁
多个线程同时请求同一个数据时，为第一个请求数据库的线程操作加锁，其他请求等待；等到第一个请求完成后，刷新缓存，其他请求就可以直接通过缓存获取数据。

11.3	缓存雪崩
大量请求缓存中大面积失效的缓存数据。
缓存同一时间大面积失效（缓存过期，缓存服务宕机），大量用户并发访问缓存时，会将请求落到数据库上，导致数据库短时间承受大量请求而崩溃。

解决方案：
	缓存数据设置随机的过期时间，防止同一时间大量数据集合失效
	集群，将数据分布在不同的缓存数据库中
	限流，通过加锁或队列来控制读数据库写缓存的线程数量

11.4	Redis的并发竞争key问题
多个Redis的客户端同时set key引起的并发问题。
解决方案：
	分布式锁
	在redis的服务端用一个状态值表示锁，对锁的占用和释放通过状态值来标识
	消息队列
	把redis.set操作放在队列中，串行化处理。

11.5	Redis缓存与数据库一致性问题
Redis写入时，先删除缓存，再更新数据库。
读写操作并发时，可能导致缓存和数据库不一致。
原数据key = value1，更新key=value2；
1、线程1更新key=value1，删除缓存key=value1；
2、线程2从缓存中读取key，由于缓存已被删除，继续从数据库读取key=value1，并写入缓存；
3、线程1更新数据库key=value2。
经过上面3步读写操作后，缓存key=value1，数据库key=value2。

解决方案：
使用队列，根据数据的唯一标识，将对同一个数据的读写操作，放入同一个jvm队列中，使同一个数据的读写操作并行处理。
12	Redis如何实现分布式锁？
目的：为了保证多台服务器在执行同一段代码时只有一台服务器执行。
方式：
使用setnx命令设置key value：不存在key设置成功返回1，已存在key设置失败返回0；
业务逻辑处理完成后使用del命令释放锁；
避免del key失败造成死锁，需要在setnx后，通过expire命令给key设置一个有效期。
为了避免设置有效期失败，可将setnx和expire命令设置为一个原子操作。

13	Redis如何实现消息队列
利用redis的list数据结果，使用lpush和rpop生产和消费消息。

14	Redis集群
集群：将同一个服务部署在多台服务器上，实现服务的高可用性。
14.1	主从模式
1个主节点master + 多个从节点slave。
14.1.1	主节点master
master主节点可读、可写，可拥有多个slave节点，写操作时会自动将数据同步给slave节点。
Master挂掉后，不影响slave节点的读服务，但redis不再对外提供写服务。
14.1.2	从节点slave
slave从节点只读，只能对应一个slave节点，只会同步master节点的数据。
Slave挂掉后，不会影响master节点和其他slave节点。
14.1.3	工作机制
当slave启动后，主动向master发送SYNC命令。
master接收到SYNC命令后在后台保存快照（RDB持久化）和缓存保存快照这段时间的命令，然后将保存的快照文件和缓存的命令发送给slave。
slave接收到快照文件和命令后加载快照文件和缓存的执行命令。
复制初始化后，master每次接收到的写命令都会同步发送给slave，保证主从数据一致性。
14.2	Sentinel(哨兵)模式
在主从模式的基础上，增加哨兵，用于监控redis集群的运行情况，在master节点宕机后，从slave节点中重新选择出新的master节点。
哨兵个数通常为奇数个，为了在master故障时投票表决是否下线该故障master节点。
14.2.1	哨兵的任务
	监控
哨兵会不断检查master和slave节点是否正常运行。
	提醒
当被监控的某个节点发生故障时，哨兵可通过API向管理员或其他应用程序发送通知。
	自动故障转移
当master节点发生故障时，哨兵会进行选举，在slave节点中选出一个新的master节点作为主服务处理redis的写操作。
14.2.2	工作机制
当使用sentinel模式的时候，客户端就不要直接连接Redis，而是连接sentinel的ip和port，由sentinel来提供具体的可提供服务的Redis实现，这样当master节点挂掉以后，sentinel就会感知并将新的master节点提供给使用者。(sentinel可以理解为一个服务注册中心)。
14.3	~~~Cluster模式


	数据库
1	数据库索引分为哪几种？组合索引有什么要注意的问题？
可以把索引理解成一张表，该表保存了主键与索引字段，并指向实体表的对应记录。
1.1	数据库索引类型
普通索引：非聚簇索引，叶子节点存放主键指针，需要回表进行二次查询。
唯一索引：索引列的值必须唯一。
组合索引：索引包含多个字段，但是只有一个索引名称。
全文索引：检索包含着一个或者多个给定单词的数据记录（不针对某个具体字段）。
覆盖索引：在一颗索引树上即可获取SQL所需的所有列数据，无需回表。
		将被查询的字段，建立到组合索引，可实现覆盖索引。

1.2	组合索引注意问题2
	最左原则：
对于组合索引（col1,col2,col3）,在查询使用时,最好将条件顺序按找索引的顺序,这样效率最高;    
 		select * from table1 where col1=A AND col2=B AND col3=D 
如果使用
where col2=B AND col1=A 
或者 
where col2=B 
将不会使用索引
	组合索引中字段的顺序，选择性越高的字段排在最前面
	组合索引的字段不要过多，如果超过4个字段，一般需要考虑拆分成多个单列索引或更为简单的组合索引
	如果where条件中是OR关系，加索引不起作用
	避免使用“OR”，否定查询，模糊查询，not in，<>等操作
	选择 where,on,group by,order by 中出现的列

2	什么是悲观锁？什么是乐观锁？如何实现悲观锁？
悲观锁：对数据的冲突采取一种悲观的态度，始终假设数据肯定会冲突，所以在数据开始读取的时候就把数据锁定住；
	共享锁：读锁，允许多个并发事物读取锁定的资源，可同时读，不可写；
	排它锁：写锁，不允许同时写，不允许写的同时读；
乐观锁：认为数据一般情况下不会造成冲突，在数据进行提交更新的时候，才会对数据的冲突与否进行检测，如果发现冲突了，才返回错误信息。

Mysql乐观锁实现：
	为数据表增加一个版本标识（int），当读取数据时，同时独处版本标识，数据每更新一次，版本标识加1；更新前，需将读取的版本标识与数据库当前版本标识进行对比，相等的情况下才予以更新，否则操作的就是过期数据；
Mysql悲观锁实现：
	首先需关闭mysql的自动提交属性(autocommit)，在事务中，只有SELECT ... FOR UPDATE 或LOCK IN SHARE MODE 同一笔数据时会等待其它事务结束后才执行，一般SELECT ... 则不受此影响。在不同的事务中同时执行包含上面两个关键字段的查询语句时，后开启的事务会被阻塞，直到先开启的事务关闭。

Java乐观锁实现：
	冲突检测和数据更新。典型的是Compare and swap(CAS)，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其他线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。

Java悲观锁实现：
	Synchronized

3	数据库关键字的执行顺序是什么？
From，on，join，where，group by，having，select，distinct，order by，limit
4	如何进行sql优化？
1、避免进行全表扫描：
	在where和order by涉及的列上建立索引；
	避免在where子句中对字段进行null值判断(空值判断会放弃使用索引而导致全表扫描)
	避免在where子句中使用!=，<>操作符和来or连接条件(原因同上)；
	In和not in也会导致全表扫描；
	模糊查询时的%也会导致全表扫描；
	在where子句中对字段进行表达式或函数操作会导致全表扫描
	适量使用索引但不能滥用索引；
	尽量使用数字型字段而不是字符型：字符型比较时开销较大；
	尽可能使用varchar代替char，变长字段存储空间小，在相对较小的空间内搜索效率较高；
	查询时应尽量避免使用select *；
	避免频繁创建和删除临时表，以减少系统表资源的消耗；
	避免大事务操作，提高系统并发能力。
5	数据库分库分表
对于大数据量并且访问频繁的表，可将其分为若干个子表；如果不进行分库分表操作，进行一次查询操作有可能就会将表锁住(悲观锁)，导致不能进行其他操作。
垂直分库：
	把相关联的一类表部署在一个库上
分表垂直分割：
	热数据和冷数据(列/字段)分为不同表存储，子表的数据结构不同
分表水平分割：
	按行分割，子表的数据结构相同，存储数据不同

6	MyISAM和InnoDB存储引擎区别
MyISAM专注性能，InnoDb专注事务。两者最大的区别就是InnoDb支持事务和行锁。
 
其他：
	MyISAM为非聚集索引，索引和数据文件分离，索引保存的是数据文件的指针；
		InnoDB为聚集索引，索引和数据文件绑定在一起，必须有主键。
	MyISAM的存储文件分别为frm(表结构)、MYD(数据文件)、MYI(索引文件)；
		InnoDB的存储文件为frm(表结构)、ibd(表的数据和索引)。
	MyISAM保存了表的总行数、InnoDB未保存表的总行数。
	系统崩溃后，MyISAM恢复数据较困难。
一般来说，如果需要事务支持、大量的update或delete操作，则选择InnoDB。
7	Mysql一个表最多支持多少个索引
	Innodb：
最多1017列，最多创建64个二级索引，单个索引最多包含16列。
	Mysiam：
最多4096列，最多创建64个二级索引，单个索引最多包含16列。

8	MySQL的binlog
binlog是记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志。
8.1	格式
 
8.1.1	Statement
基于SQL语句的复制，每一条会修改数据的SQL都会记录在binlog日志中。
	优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。
	缺点：必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在slave得到和在master端执行时候相同的结果。
8.1.2	Row
不记录sql语句及上下文信息，仅保存哪条记录被修改了。
	优点：日志会很清楚地记录下每一行数据修改的细节。
	缺点：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容。
8.1.3	Mixed
一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种。
8.2	查看binlog日志文件(mysqlbinlog)
Statement：mysqlbinlog mysql-bin.000001 
Row：mysqlbinlog -vv mysql-bin.000001 

9	MySQL主从复制如何实现
主从复制时，在主从数据库拷贝的内容就是binlog文件中的内容。在主从复制过程中通过网络把主节点的binlog文件传输到从节点，从节点会执行接收到的binlog文件中的内容，达到主从数据一致的效果。
主库有一个log dump线程(I/O)，将binlog传给从库。
从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log,SQL线程从relay log里面读取内容，写入从库的数据库。
9.1	主从数据不一致
	网络延迟
	写主节点、读从节点，由于从节点要同步主节点的binlog，会因为时间前后关系，造成不一致。
9.2	如何解决
	主从复制配置成半复制，即要等到从节点成功执行后主节点再返回写成功(把主节点写操作和从节点复制做成同步操作)。
	从节点只做备份使用，强制读主节点 。
	程序允许一定时间内的数据不一致情况。


10	索引类型
	FullText
全文索引，只有MyISAM支持。
为了解决WHERE name LIKE “%word%"这类针对文本的模糊查询效率较低的问题。
	Hash
一次定位，高效，但仅适用于”=”、”in”条件，在范围查询、排序等情况下效率低下。
	BTREE
树形结构，二分查找，B+树，磁盘IO少，效率高。
	RTREE
仅支持geometry数据类型，RTREE的优势在于范围查找。
11	数据库的锁机制
11.1	锁的类型
11.1.1	表级锁
直接锁定整个表，锁粒度大，并发效率低。
11.1.2	行级锁（记录锁）
锁定一行数据，所粒度小，容易发生死锁。
11.1.3	页级锁
锁定一页的数据，每个叶子节点的单位页，叶子节点上面存放了多个记录行，数据存储是按照一页一页来的，每次锁定一页的数据，其实就是相邻的数据，开销和加锁时间界于表锁和行锁之间。 

 
11.2	间隙锁
向表中新增一条数据age=20，这条数据在本来是没有的，在insert还没有提交的时候去select * from tableA a where a.age>15 and a.age<25，这个时候就会触发间隙锁，我们必须等待insert提交后才能执行select语句。
   
	锁的是索引叶子节点的next指针，或者说间隙锁是一个在索引记录之间的间隙上的锁；
	解决了mysql重复读级别下的幻读问题；
	防止select * from z where b = 6出现幻读
 
11.3	MyISAM锁机制(表锁)
查询语句：给相关表加读锁，允许并发读，阻塞并发写。
更新操作：给相关表加写锁，阻塞并发读写操作。
11.4	InnoDb锁机制(表锁，行锁)
	通过给索引项加锁来实现行锁。
	只有在查询数据，检索条件走索引时，才使用行锁，否则走表锁。
	行锁是针对索引加锁，不是针对记录加的锁。即使访问的是不同行，但如果它们索引相同，还是会出现锁冲突。、
在默认的可重复读隔离级别下：
执行查询语句(SELECT)前，由于 MVCC(多版本控制)的方式，什么锁都不会加。
在执行更新操作(UPDATE、DELETE、INSERT 等)前，会自动给涉及的行加写锁，此时会阻塞其他用户的写操作，但是通过 MVCC(多版本控制)的方式允许读操作。


